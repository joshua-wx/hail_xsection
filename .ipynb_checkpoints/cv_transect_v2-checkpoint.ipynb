{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "import warnings\n",
    "import json\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2 as cv\n",
    "import scipy\n",
    "from skimage import measure, draw, filters, morphology\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '/home/meso/data/cross-section-photos/analysis/photos'\n",
    "out_root = '/home/meso/data/cross-section-photos/analysis/pipeline_img'\n",
    "stats_root = '/home/meso/data/cross-section-photos/analysis/pipeline_stats'\n",
    "centres_json_ffn = '/home/meso/data/cross-section-photos/analysis/photos/melb_20200119_hail.json'\n",
    "reference_csv_ffn = '/home/meso/data/cross-section-photos/analysis/photos/xsec_reference_measurements.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_by_shoelace(x, y):\n",
    "    \"Assumes x,y points go around the polygon in one direction\"\n",
    "    return abs( sum(i * j for i, j in zip(x,             y[1:] + y[:1]))\n",
    "               -sum(i * j for i, j in zip(x[1:] + x[:1], y            ))) / 2\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    return np.convolve(a, np.ones((n,))/n, mode='same')\n",
    "     \n",
    "def remove_edge_peak(lum_data, peaks, limit=50):\n",
    "    \n",
    "    #define edge\n",
    "    edge_idx = np.where(lum_data>0)[0][-1]\n",
    "    #check if last peak is within the limit of the edge\n",
    "    if (edge_idx - peaks[-1]) < limit:\n",
    "        return peaks[:-1]\n",
    "    else:\n",
    "        return peaks\n",
    "\n",
    "def find_peak_width(lum_data, peaks, fall_perc = 0.20, merge_dist=15):\n",
    "    \n",
    "    left_pass_1 = []\n",
    "    right_pass_1 = []\n",
    "    \n",
    "    #find edge\n",
    "    edge_idx = np.where(lum_data>0)[0][-1]\n",
    "    \n",
    "    for peak_idx in peaks:\n",
    "        #extract peak lumosity\n",
    "        peak_lum = lum_data[peak_idx]\n",
    "        #extract threshold for lumosity\n",
    "        peak_lower_limit = peak_lum - (peak_lum*fall_perc)\n",
    "        #setup arrays for detecting edges of dry growth region\n",
    "        lum_data_left = lum_data.copy()\n",
    "        lum_data_left[peak_idx:] = peak_lum #replace lum values on the right side of the peak with peak_lum, preserving the left side\n",
    "        lum_data_right = lum_data.copy()\n",
    "        lum_data_right[:peak_idx] = peak_lum #replace lum values on the left side of the peak with peak_lum, preserving the right side\n",
    "        #find sides of peak\n",
    "        #right\n",
    "        try:\n",
    "            peak_right = np.where(lum_data_right<peak_lower_limit)[0][0] #use first value below the threshold to find the right point. Will always work because of background\n",
    "        except:\n",
    "            #take the argmin if this fails\n",
    "            peak_right = np.argmin(lum_data_right)\n",
    "        #enforce edge limit on peak right\n",
    "        if peak_right > edge_idx:\n",
    "            peak_right = edge_idx\n",
    "        #left\n",
    "        try:\n",
    "            peak_left = np.where(lum_data_left<peak_lower_limit)[0][-1] #use last value below threshold to find left point\n",
    "        except:\n",
    "            #cases for close peaks to centre, and transect does not reduce below threshold.\n",
    "            peak_left = peak_idx - (peak_right-peak_idx) #reflection of right peak\n",
    "        #enforce 0\n",
    "        if peak_left < 0:\n",
    "            peak_left = 0        \n",
    "\n",
    "        #append\n",
    "        left_pass_1.append(peak_left)\n",
    "        right_pass_1.append(peak_right)\n",
    "\n",
    "    left_pass_1  = np.array(left_pass_1)\n",
    "    right_pass_1 = np.array(right_pass_1)\n",
    "    peak_pass_1 = np.array(peaks)\n",
    "    \n",
    "    #merge overlapping peaks\n",
    "    left_pass_2 = []\n",
    "    right_pass_2 = []\n",
    "    peak_pass_2 = []\n",
    "    proc_flag = np.zeros_like(left_pass_1, dtype=bool)\n",
    "    for i, peak in enumerate(peak_pass_1):\n",
    "        #check if already processes\n",
    "        if proc_flag[i]:\n",
    "            continue\n",
    "        #find if centre overlaps with multiple left/right regions\n",
    "        overlap = np.where(np.logical_and(left_pass_1<peak, right_pass_1>peak))[0]\n",
    "        #find min of those points\n",
    "        left_pass_2.append(np.min(left_pass_1[overlap]))\n",
    "        right_pass_2.append(np.max(right_pass_1[overlap]))\n",
    "        overlap_peak_lum = lum_data[peak_pass_1[overlap]] #find luminosity values of overlapping peaks\n",
    "        peak_pass_2.append(peak_pass_1[overlap[np.argmax(overlap_peak_lum)]]) #only append the index of the highest luminosity value\n",
    "        #assign as processed\n",
    "        proc_flag[overlap] = True\n",
    "    \n",
    "    #filtering to remove very narrow peaks and peaks centred very close to the edge (using a 20pix limit)\n",
    "    left_pass_3 = []\n",
    "    right_pass_3 = []\n",
    "    peak_pass_3 = []\n",
    "    for i, peak in enumerate(peak_pass_2):\n",
    "        width = right_pass_2[i] - left_pass_2[i]\n",
    "        #check size of peak width and distance from edge\n",
    "        if (edge_idx - peak) > 20 and width > 20:\n",
    "            left_pass_3.append(left_pass_2[i])\n",
    "            right_pass_3.append(right_pass_2[i])\n",
    "            peak_pass_3.append(peak_pass_2[i])\n",
    "\n",
    "    #output\n",
    "    left_array = np.array(left_pass_3)\n",
    "    right_array = np.array(right_pass_3)\n",
    "    peak_array = np.array(peak_pass_3)\n",
    "        \n",
    "    return left_array, right_array, peak_array, edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(image_ffn, c_coord, ref_coord, emb_coord, img_ref_mm):\n",
    "    img_fn = os.path.basename(image_ffn)\n",
    "    img_id = img_fn[0:2]\n",
    "    print('processing', image_ffn)\n",
    "    #unpack inputs\n",
    "    cx = c_coord[0]\n",
    "    cy = c_coord[1]\n",
    "    \n",
    "    #work out pixel scaling\n",
    "    ref_coord_x = ref_coord[0]\n",
    "    ref_coord_y = ref_coord[1]\n",
    "    ref_len = np.sqrt((ref_coord_x[0]-ref_coord_x[1])**2 + (ref_coord_y[0]-ref_coord_y[1])**2)\n",
    "    ref_pix_mm = ref_len/img_ref_mm\n",
    "    #work out embryo sa\n",
    "    if emb_coord is None:\n",
    "        emb_sa = None\n",
    "    else:\n",
    "        emb_coord_x = emb_coord[0] + [emb_coord[0][0]]\n",
    "        emb_coord_y = emb_coord[1] + [emb_coord[1][0]]\n",
    "        emb_sa = area_by_shoelace(emb_coord_x, emb_coord_y)\n",
    "\n",
    "    #transform into hsv colorspace\n",
    "    img_data = cv.imread(image_ffn)\n",
    "    img_data_hls = cv.cvtColor(img_data, cv.COLOR_BGR2HLS)\n",
    "    lum_img = img_data_hls[:,:,1]\n",
    "    img_size = np.shape(lum_img)\n",
    "    lum_img_smooth = filters.gaussian(lum_img, sigma=4)*255\n",
    "    \n",
    "    #define and plot transect lines\n",
    "    pixel_range   = np.max(img_size) #pixels (max possible distance)\n",
    "    azimuth_spacing = 5 #degrees\n",
    "    #init azimuth list\n",
    "    azimuth_dim = np.arange(0,360,azimuth_spacing)\n",
    "    range_dim = np.arange(0,pixel_range)\n",
    "    #init range element size\n",
    "    range_bin = range_dim[1] - range_dim[0]\n",
    "    azi_bin = azimuth_dim[1] - azimuth_dim[0]\n",
    "    size_dim = np.zeros_like(range_dim)\n",
    "    for i, bin_range in enumerate(range_dim):\n",
    "        size_dim[i] = (((bin_range+(range_bin/2))**2)*math.pi - ((bin_range-(range_bin/2))**2)*math.pi)/360*azi_bin\n",
    "    \n",
    "    \n",
    "    #init azimuth_range array\n",
    "    layer_array = np.zeros((pixel_range, len(azimuth_dim))) -1 #set all to be outside\n",
    "    \n",
    "    \n",
    "    line_x_list = []\n",
    "    line_y_list = []\n",
    "    line_lum_list = []\n",
    "    peaks_idx_list = []\n",
    "    peaks_x_list = []\n",
    "    peaks_y_list = []\n",
    "    peaks_azi_list = []\n",
    "    edge_idx_list = []\n",
    "    cl_x_list = []\n",
    "    cl_y_list = []\n",
    "    cr_x_list = []\n",
    "    cr_y_list = []\n",
    "    c_width_list = []\n",
    "    \n",
    "    #for each azimuth\n",
    "    for i, azi in enumerate(azimuth_dim):\n",
    "        # create indicies for lines from centroid along search azimuth rays\n",
    "        end_x    = int(cx + pixel_range*math.cos(math.radians(azi))) #2x ensures it already reaches the edges\n",
    "        end_y    = int(cy + pixel_range*math.sin(math.radians(azi)))\n",
    "        #generate line points\n",
    "        line_x   = np.linspace(cx, end_x, pixel_range).astype(np.int)\n",
    "        line_y   = np.linspace(cy, end_y, pixel_range).astype(np.int)\n",
    "        #enforce boundaries\n",
    "        mask_x = np.logical_and(line_x >= 0, line_x <= img_size[1]-1)\n",
    "        mask_y = np.logical_and(line_y >= 0, line_y <= img_size[0]-1)\n",
    "        mask = np.logical_and(mask_x, mask_y)\n",
    "        line_x = line_x[mask]\n",
    "        line_y = line_y[mask]\n",
    "        \n",
    "        # extract data along\n",
    "        line_lum = lum_img_smooth[line_y, line_x].astype(int)\n",
    "        #measure peaks\n",
    "        peaks_idx, _ = scipy.signal.find_peaks(line_lum, prominence=30, distance=30, height=100)\n",
    "\n",
    "        #find width of peaks and combine overlapping peaks\n",
    "        left_idx, right_idx, new_peak_idx, edge_idx = find_peak_width(line_lum, peaks_idx)        \n",
    "        \n",
    "        #add to layer_array\n",
    "        layer_vec = np.zeros(pixel_range,)\n",
    "        for j,_ in enumerate(new_peak_idx):\n",
    "            layer_vec[left_idx[j]:right_idx[j]+1] = 1\n",
    "        layer_vec[edge_idx:] = -1\n",
    "        layer_array[:,i] = layer_vec\n",
    "\n",
    "        #check for valid peaks\n",
    "        if len(new_peak_idx) == 0:\n",
    "            continue\n",
    "        \n",
    "        #store\n",
    "        line_x_list.append(line_x)\n",
    "        line_y_list.append(line_y)\n",
    "        line_lum_list.append(line_lum)\n",
    "        peaks_idx_list.append(new_peak_idx)\n",
    "        peaks_x_list.append(line_x[new_peak_idx])\n",
    "        peaks_y_list.append(line_y[new_peak_idx])\n",
    "        peaks_azi_list.append(np.zeros_like(new_peak_idx)+azi)\n",
    "        cl_x_list.append(line_x[left_idx])\n",
    "        cl_y_list.append(line_y[left_idx])\n",
    "        cr_x_list.append(line_x[right_idx])\n",
    "        cr_y_list.append(line_y[right_idx])\n",
    "        edge_idx_list.append(edge_idx)\n",
    "    \n",
    "    #flatten centre info arrays\n",
    "    cl_x_array = np.concatenate(cl_x_list).ravel()\n",
    "    cl_y_array = np.concatenate(cl_y_list).ravel()\n",
    "    cr_x_array = np.concatenate(cr_x_list).ravel()\n",
    "    cr_y_array = np.concatenate(cr_y_list).ravel()\n",
    "    peak_idx_array = np.concatenate(peaks_idx_list).ravel()\n",
    "    peak_x_array = np.concatenate(peaks_x_list).ravel()\n",
    "    peak_y_array = np.concatenate(peaks_y_list).ravel()\n",
    "    peaks_azi_array = np.concatenate(peaks_azi_list).ravel()\n",
    "    \n",
    "    #remove small regions from layer_array\n",
    "    \"\"\"\n",
    "    #IMPROVE HERE- remove objects with an azimuthal width smaller than 3?\n",
    "    \"\"\"\n",
    "    layer_valid = morphology.remove_small_objects(layer_array==1, min_size=100)\n",
    "    layer_array[layer_valid]=2\n",
    "    \n",
    "    #compute range density\n",
    "    range_density = np.sum(layer_valid, axis=1)\n",
    "    #smooth\n",
    "    range_density_smooth = moving_average(range_density, 7)\n",
    "    #find peaks in range density\n",
    "    layer_peaks_idx, _ = scipy.signal.find_peaks(range_density_smooth, prominence=5)\n",
    "    #for each peak, centre of mass and total count\n",
    "    layer_lower_min_idx = []\n",
    "    layer_upper_min_idx = []\n",
    "    layer_sa_list = []\n",
    "    layer_weighted_centre_list = []\n",
    "    for i, peak in enumerate(layer_peaks_idx):\n",
    "        #find index of upper and lower minimum\n",
    "        if i==0:\n",
    "            lower_min = np.where(range_density_smooth>0)[0][0]\n",
    "        else:\n",
    "            lower_min = layer_peaks_idx[i-1] + np.argmin(range_density_smooth[layer_peaks_idx[i-1]:peak])\n",
    "            \n",
    "        if i+1==len(layer_peaks_idx):\n",
    "            upper_min = np.where(range_density_smooth>0)[0][-1]\n",
    "        else:\n",
    "            upper_min = peak + np.argmin(range_density_smooth[peak:layer_peaks_idx[i+1]])\n",
    "        layer_lower_min_idx.append(lower_min)\n",
    "        layer_upper_min_idx.append(upper_min)\n",
    "        #calculate count\n",
    "        layer_sa = range_density[lower_min:upper_min+1]*size_dim[lower_min:upper_min+1]\n",
    "        layer_sa_list.append(np.sum(layer_sa))\n",
    "        #calculate centre of mass radius\n",
    "        radius_sum = np.sum(layer_sa*range_dim[lower_min:upper_min+1])\n",
    "        layer_weighted_centre_list.append(radius_sum/np.sum(layer_sa))\n",
    "    \n",
    "    #plot initial image\n",
    "    fig = plt.figure(facecolor='white',figsize=[20, 16])\n",
    "    plt.subplot(231)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.imshow(lum_img)\n",
    "    plt.plot(cx, cy, 'r*')\n",
    "    try:\n",
    "        plt.plot(emb_coord_x, emb_coord_y, 'r-')\n",
    "    except:\n",
    "        #no dry embryo\n",
    "        pass\n",
    "    plt.plot(ref_coord_x, ref_coord_y, 'k--')\n",
    "    plt.title(f'{img_id} lumosity of original image')\n",
    "    \n",
    "    #plot azimuth data on image\n",
    "    plt.subplot(232)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.imshow(lum_img_smooth)\n",
    "    for i, _ in enumerate(cl_x_array):\n",
    "        #mark peaks\n",
    "        plt.plot(peak_x_array[i], peak_y_array[i], 'b.')\n",
    "        #mark edges\n",
    "        plt.plot([cl_x_array[i],cr_x_array[i]],[cl_y_array[i],cr_y_array[i]], 'r-')        \n",
    "    plt.title('transect peaks and layer widths')\n",
    "    \n",
    "    \n",
    "    #plot azimuth/range arrat on image\n",
    "    plt.subplot(233)\n",
    "    plt.pcolor(azimuth_dim, range_dim, layer_array)\n",
    "    plt.xlabel('Azimuth (deg)')\n",
    "    plt.ylabel('Range (pix.)')\n",
    "    plt.title('layer locations in azimuth, range space')\n",
    "    \n",
    "    \n",
    "    #plot range density\n",
    "    plt.subplot(234)  \n",
    "    plt.plot(range_density_smooth, range_dim, 'b-', label='density')\n",
    "    plt.plot(range_density_smooth[layer_peaks_idx], range_dim[layer_peaks_idx], 'ro', label='peak')\n",
    "    plt.plot(range_density_smooth[layer_lower_min_idx], range_dim[layer_lower_min_idx], 'gx', label='peak lower limit')\n",
    "    plt.plot(range_density_smooth[layer_upper_min_idx], range_dim[layer_upper_min_idx], 'b+', label='peak upper limit')\n",
    "    plt.plot(range_density_smooth[np.array(layer_weighted_centre_list).astype('int')], layer_weighted_centre_list, 'ko', label='area weighted centre of peak')\n",
    "    plt.xlabel('Density (pix.)')\n",
    "    plt.ylabel('Range (pix.)')\n",
    "    plt.title('layer seperation in density, range space')\n",
    "    plt.legend()\n",
    "    \n",
    "    #draw equivalent circular hail\n",
    "    ax = plt.subplot(235)\n",
    "    ax.set_xlim((-35,35))\n",
    "    ax.set_ylim((-35,35))\n",
    "    ax.set_xlabel('(mm)')\n",
    "    ax.set_ylabel('(mm)')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_facecolor('k')\n",
    "    #draw entire hail\n",
    "    mean_edge_radius = np.mean(edge_idx_list)/ref_pix_mm\n",
    "    max_edge_radius = np.max(edge_idx_list)/ref_pix_mm\n",
    "    n_layers = len(layer_sa_list)\n",
    "    background = plt.Circle((0, 0), mean_edge_radius, color=[0.5,0.5,0.5])\n",
    "    ax.add_artist(background)\n",
    "    total_dry_sa = 0\n",
    "    for i in range(len(layer_sa_list)-1, -1, -1): #loop backwards\n",
    "        r = layer_weighted_centre_list[i]\n",
    "        sa = layer_sa_list[i]\n",
    "        total_dry_sa += sa/(ref_pix_mm**2)\n",
    "        r_inner = math.sqrt(r**2-(sa/(2*math.pi)))/ref_pix_mm\n",
    "        r_outer = math.sqrt((sa/(2*math.pi))+r**2)/ref_pix_mm\n",
    "        circle_inner = plt.Circle((0, 0), r_inner, color=[0.5,0.5,0.5])\n",
    "        circle_outer = plt.Circle((0, 0), r_outer, color='w')\n",
    "        ax.add_artist(circle_outer)\n",
    "        ax.add_artist(circle_inner)\n",
    "    #draw embryo\n",
    "    if emb_sa is not None:\n",
    "        r_embryo = np.sqrt(emb_sa/math.pi)/ref_pix_mm\n",
    "        circle_embryo = plt.Circle((0, 0), r_embryo, color='w')\n",
    "        ax.add_artist(circle_embryo)\n",
    "    plt.title('equivalent circular hail xsection (white=dry, grey=wet)')\n",
    "    \n",
    "    \n",
    "    #draw scaled hail image in greyscale\n",
    "    ax = plt.subplot(236)\n",
    "    ax.set_xlim((-35,35))\n",
    "    ax.set_ylim((-35,35))\n",
    "    ax.set_xlabel('(mm)')\n",
    "    ax.set_ylabel('(mm)')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_facecolor('k')\n",
    "    x = (np.arange(0,img_size[1])-int(img_size[1]/2))/ref_pix_mm\n",
    "    y = (np.arange(0,img_size[0])-int(img_size[0]/2))/ref_pix_mm\n",
    "    plt.pcolor(x, y, np.flipud(lum_img), cmap='gray')\n",
    "    plt.title('scaled cross section')\n",
    "    \n",
    "    plt.savefig(f'{out_root}/analysis_{os.path.basename(image_ffn)}')\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    gc.collect()\n",
    "    #save some stats\n",
    "    np.savez(f'{stats_root}/stats_{img_id}.npz', mean_edge_radius=mean_edge_radius,\n",
    "            max_edge_radius=max_edge_radius, total_dry_sa=total_dry_sa, n_layers=n_layers)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no dry embryo for 2\n",
      "no dry embryo for 5\n",
      "no dry embryo for 9\n",
      "no dry embryo for 24\n",
      "no dry embryo for 25\n",
      "no dry embryo for 26\n",
      "no dry embryo for 27\n",
      "no dry embryo for 29\n",
      "no dry embryo for 34\n"
     ]
    }
   ],
   "source": [
    "#build arguments\n",
    "\n",
    "#read reference sizes\n",
    "df = pd.read_csv(reference_csv_ffn)\n",
    "\n",
    "#build image file and centroid arguments from json\n",
    "image_args_list = []\n",
    "with open(centres_json_ffn) as json_fh:  \n",
    "    data = json.load(json_fh)\n",
    "    for item in data.keys():\n",
    "        #extract image name and id\n",
    "        img_fn = data[item]['filename']\n",
    "        img_id = int(img_fn[0:2])\n",
    "        #init objects\n",
    "        c_coord = None\n",
    "        ref_coord = None\n",
    "        emb_coord = None\n",
    "        #extract shape objects\n",
    "        for shape in data[item]['regions']:\n",
    "            shape = shape['shape_attributes']\n",
    "            if shape['name'] == 'point':\n",
    "                c_coord = [shape['cx'], shape['cy']]\n",
    "            if shape['name'] == 'polygon':\n",
    "                emb_coord = [shape['all_points_x'], shape['all_points_y']]\n",
    "            if shape['name'] == 'polyline':\n",
    "                ref_coord = [shape['all_points_x'], shape['all_points_y']]    \n",
    "        if emb_coord == None:\n",
    "            print('no dry embryo for', img_id)\n",
    "        #check for missing metadata\n",
    "        if c_coord == None or ref_coord == None:\n",
    "            print('error: missing json data for if', img_id)\n",
    "            continue\n",
    "        \n",
    "        #extract reference measurement\n",
    "        try:\n",
    "            img_ref_mm = float(df.size_mm[df.id==img_id])\n",
    "        except:\n",
    "            print('error: failed to find reference measurement to match id', img_id)\n",
    "            continue\n",
    "        #build args\n",
    "        image_args_list.append((f'{image_folder}/{img_fn}', c_coord, ref_coord, emb_coord, img_ref_mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /home/meso/data/cross-section-photos/analysis/photos/40.png\n",
      "processing /home/meso/data/cross-section-photos/analysis/photos/41.png\n",
      "processing /home/meso/data/cross-section-photos/analysis/photos/42.png\n",
      "processing /home/meso/data/cross-section-photos/analysis/photos/43.png\n"
     ]
    }
   ],
   "source": [
    "for item in image_args_list[39:]:\n",
    "    worker(*item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hailpixel] *",
   "language": "python",
   "name": "conda-env-hailpixel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
