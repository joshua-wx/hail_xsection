{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook is used to process hail cross-section photographs/annotations.\\nGenerates measurements of layer area and conversion to circular representation\\n\\nAuthor: Joshua Soderholm.\\nContact: joshua.soderholm at bom.gov.au\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook is used to process hail cross-section photographs/annotations.\n",
    "Generates measurements of layer area and conversion to circular representation\n",
    "\n",
    "Author: Joshua Soderholm.\n",
    "Contact: joshua.soderholm at bom.gov.au\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "import gc\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "# CV libraries\n",
    "import cv2 as cv\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# maths libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import draw, filters, morphology, transform\n",
    "from shapely.geometry import Polygon\n",
    "from scipy import interpolate\n",
    "\n",
    "# turn off warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup paths for inputs\n",
    "\n",
    "# folder containing images of a unique size\n",
    "image_folder = \"/home/meso/data/cross-section-paper-data/analysis/photos\"\n",
    "# csv file containing reference measurements\n",
    "reference_csv_ffn = \"/home/meso/data/cross-section-paper-data/analysis/photos/xsec_reference_measurements.csv\" \n",
    "# json output from VIA tool containing (1) embryo centre (2) embryo polygon (3) measurement line\n",
    "via_json_ffn = \"/home/meso/data/cross-section-paper-data/analysis/photos/melb_20200119_hail.json\"  \n",
    "\n",
    "# setup paths for outputs\n",
    "\n",
    "# annotated images\n",
    "out_root = \"/home/meso/data/cross-section-paper-data/analysis/paper/pipeline_img\"  \n",
    "# npy files containing stats\n",
    "stats_root = \"/home/meso/data/cross-section-paper-data/analysis/paper/pipeline_stats\"\n",
    "# images for composite figure\n",
    "composite_eq_root = \"/home/meso/data/cross-section-paper-data/analysis/paper/composite_eq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_shapely(x, y):\n",
    "    \"\"\"\n",
    "    Calculate area within polygon defined by x,y points\n",
    "    Assumes x,y points go around the polygon in one direction.\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    x: list of floats\n",
    "        x coordinates list of polygon\n",
    "    y: list of floats\n",
    "        y coordinates list of polygon\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    float\n",
    "        area of polygon\n",
    "    \"\"\"\n",
    "    poly = Polygon(zip(x,y))\n",
    "    return poly.area\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    \"\"\"\n",
    "    return the moving average of a 1D vector.\n",
    "    total length is preserved by using same values on edges.\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    a: ndarray (1,n)\n",
    "        vector to apply moving average to\n",
    "    n: int\n",
    "        window size\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    ndarray (1,n)\n",
    "        a with moving average filter applied\n",
    "    \"\"\"\n",
    "    return np.convolve(a, np.ones((n,)) / n, mode=\"same\")\n",
    "\n",
    "def _find_layer_edge(data, threshold, edge_idx, mode='left'):\n",
    "    \"\"\"\n",
    "    returns the index where data first falls below the threshold (and a argmin if this fails).\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    data: ndarray (1,n)\n",
    "        array to\n",
    "    threshold: float\n",
    "        data threhold for finding layer edge\n",
    "    edge_idx: int\n",
    "        index of edge pixel\n",
    "    mode: string\n",
    "        either 'left' or 'right'. defermines if the first or last index from np.where is used\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    layer_edge_idx: int\n",
    "        index of the layer edge\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # find the first/last data index below the threshold, which marks the right/left edge of the layer\n",
    "        if mode=='left':\n",
    "            layer_edge_idx = np.where(data < threshold)[0][-1]\n",
    "        else:\n",
    "            layer_edge_idx = np.where(data < threshold)[0][0]\n",
    "    except Exception as e:\n",
    "        # take the argmin if this fails\n",
    "        layer_edge_idx = np.argmin(data)\n",
    "    # enforce edge limit on peak right\n",
    "    if layer_edge_idx > edge_idx:\n",
    "        layer_edge_idx = edge_idx\n",
    "    return layer_edge_idx\n",
    "            \n",
    "            \n",
    "def find_peak_edges(data, peaks, pixel_size):\n",
    "\n",
    "    \"\"\"\n",
    "    Find the width (left and right edges) of peaks within tha 1D array provided.\n",
    "    Also returns the edge pixel (last pixel inside the hailstone).\n",
    "    A secondary filtering is applied to all peaks\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    data: ndarray (1,n)\n",
    "        1D vector from which peaks have been identified\n",
    "    peaks: ndarray (1,m)\n",
    "        1D array of peak indices\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    left_array: ndarray (1,p)\n",
    "        array of indicies for the left hand edge of filtered peak indicies\n",
    "    right_array: ndarray (1,p)\n",
    "        array of indicies for the right hand edge of filtered peak indicies\n",
    "    peak_array: ndarray (1,p)\n",
    "        filtered array of peak indicies\n",
    "\n",
    "    edge_idx: int\n",
    "        index of edge pixel\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # config\n",
    "    fall_perc = 0.30  # luminosity threshold use to find peak width (percentage)\n",
    "    edge_dist = 1*pixel_size  # minimum distance a peak must be from the edge (mm)\n",
    "    \"\"\"\n",
    "    First pass\n",
    "    (1) Find the edge pixel\n",
    "    (2) Find the left and right edges using the first pixel away from the peak which falls below the threshold.\n",
    "    If this fails, use the argmin\n",
    "    \"\"\"\n",
    "    \n",
    "    #init\n",
    "    left_pass_1 = []\n",
    "    right_pass_1 = []\n",
    "\n",
    "    # find edge pixel (first zero value)\n",
    "    edge_idx = np.where(data > 0)[0][-1]\n",
    "\n",
    "    #for each peak\n",
    "    for peak_idx in peaks:\n",
    "        # extract peak lumosity\n",
    "        peak_lum = data[peak_idx]\n",
    "        # extract threshold for lumosity\n",
    "        peak_lower_limit = peak_lum - (peak_lum * fall_perc)\n",
    "        #\n",
    "        # right side\n",
    "        #\n",
    "        data_right = data.copy()\n",
    "        # replace lum values on the left side of the peak with peak_lum, preserving the right side\n",
    "        data_right[\n",
    "            :peak_idx\n",
    "        ] = peak_lum \n",
    "        #find right index\n",
    "        layer_right_edge_idx = _find_layer_edge(data_right, peak_lower_limit, edge_idx, mode='right')\n",
    "        right_pass_1.append(layer_right_edge_idx)\n",
    "        #\n",
    "        # left side\n",
    "        #\n",
    "        data_left = data.copy()\n",
    "        # replace lum values on the right side of the peak with peak_lum, preserving the left side\n",
    "        data_left[\n",
    "            peak_idx:\n",
    "        ] = peak_lum  \n",
    "        #find left index\n",
    "        layer_left_edge_idx = _find_layer_edge(data_left, peak_lower_limit, edge_idx, mode='left')\n",
    "        left_pass_1.append(layer_left_edge_idx)\n",
    "    #convert to arrays\n",
    "    left_pass_1 = np.array(left_pass_1)\n",
    "    right_pass_1 = np.array(right_pass_1)\n",
    "    peak_pass_1 = np.array(peaks)\n",
    "\n",
    "    \"\"\"\n",
    "    Second pass\n",
    "    # merge overlapping peaks\n",
    "    \"\"\"\n",
    "    \n",
    "    # init\n",
    "    left_pass_2 = []\n",
    "    right_pass_2 = []\n",
    "    peak_pass_2 = []\n",
    "    proc_flag = np.zeros_like(left_pass_1, dtype=bool) #used to mark if peak has already been processed\n",
    "    \n",
    "    #loop through each peak\n",
    "    for i, peak in enumerate(peak_pass_1):\n",
    "        # check if already processed\n",
    "        if proc_flag[i]:\n",
    "            continue\n",
    "        #\n",
    "        # (1) check if layer extends from the centre (erase and skip)\n",
    "        #\n",
    "        if left_pass_1[i] == 0:\n",
    "            # write -999 which removed this peak in pass 3 (using the width)\n",
    "            left_pass_1[i] = -999\n",
    "            right_pass_1[i] = -999\n",
    "            continue\n",
    "        #\n",
    "        # (2) find if layer edges overlap with other layers\n",
    "        #\n",
    "        current_left = left_pass_1[i]\n",
    "        current_right = right_pass_1[i]\n",
    "        # find other overlaps on the left side of the current peak\n",
    "        overlap_left = np.logical_and(\n",
    "            current_left <= right_pass_1, peak >= peak_pass_1\n",
    "        ) \n",
    "        # find other overlaps on the right side of the current peak\n",
    "        overlap_right = np.logical_and(\n",
    "            current_right >= left_pass_1, peak <= peak_pass_1\n",
    "        )\n",
    "        # combine overlaps and index\n",
    "        overlap = np.where(np.logical_or(overlap_left, overlap_right))[0]  \n",
    "\n",
    "        # find min of those points\n",
    "        left_pass_2.append(np.min(left_pass_1[overlap]))\n",
    "        right_pass_2.append(np.max(right_pass_1[overlap]))\n",
    "        overlap_peak_lum = data[\n",
    "            peak_pass_1[overlap]\n",
    "        ]  # find luminosity values of overlapping peaks\n",
    "        peak_pass_2.append(\n",
    "            peak_pass_1[overlap[np.argmax(overlap_peak_lum)]]\n",
    "        )  # only append the index of the highest luminosity value\n",
    "        # assign as processed\n",
    "        proc_flag[overlap] = True\n",
    "\n",
    "    \"\"\"\n",
    "    Third pass\n",
    "    - remove layers close to the edge\n",
    "    \"\"\"\n",
    "    left_pass_3 = []\n",
    "    right_pass_3 = []\n",
    "    peak_pass_3 = []\n",
    "    for i, left_edge in enumerate(left_pass_2):\n",
    "        # check distance from edge to peak\n",
    "        if (edge_idx - left_edge) > edge_dist:\n",
    "            left_pass_3.append(left_pass_2[i])\n",
    "            right_pass_3.append(right_pass_2[i])\n",
    "            peak_pass_3.append(peak_pass_2[i])\n",
    "            \n",
    "    # output\n",
    "    left_array = np.array(left_pass_3)\n",
    "    right_array = np.array(right_pass_3)\n",
    "    peak_array = np.array(peak_pass_3)\n",
    "\n",
    "    return left_array, right_array, peak_array, edge_idx\n",
    "\n",
    "    \n",
    "def process_layers(layer_peaks_idx, layer_density_smooth, range_dim, area_dim):\n",
    "    \n",
    "    \"\"\"\n",
    "    For a given list of layer peaks, determine the edges of each peak, the surface area and the weighted centre\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    layer_peaks_idx: ndarray (1,m)\n",
    "        array of indicies for layer peak locations\n",
    "    layer_density_smooth: ndarray (n)\n",
    "        1D array of smoothed opaque layer count (across all transects)\n",
    "    range_dim: list (n)\n",
    "        list of range dimension (pixel units)\n",
    "    area_dim: ndarray (n)\n",
    "        1D array of pixel area for each range bin\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    layer_left_edge_idx: list (m)\n",
    "        array of indicies for the left hand edge of filtered peak indicies (pixel units)\n",
    "    layer_right_edge_idx: list (m)\n",
    "        array of indicies for the right hand edge of filtered peak indicies (pixel units)\n",
    "    layer_sa_list: list (m)\n",
    "        list of surface area for each opaque layer (pixel units)\n",
    "    layer_weighted_centre_list: list (m)\n",
    "        list of weighted centroid (index along range dim) for each opaque layer\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # for each layer peak, find layer edges centre of mass and total count\n",
    "    layer_left_edge_idx = []\n",
    "    layer_right_edge_idx = []\n",
    "    layer_sa_list = []\n",
    "    layer_weighted_centre_list = []\n",
    "    for i, peak in enumerate(layer_peaks_idx):\n",
    "        # find index of upper and lower minimum\n",
    "        if i == 0:\n",
    "            left_edge = np.where(layer_density_smooth > 0)[0][\n",
    "                0\n",
    "            ]  # first nonzero value before the first peak\n",
    "        else:\n",
    "            left_edge = layer_peaks_idx[i - 1] + np.argmin(\n",
    "                layer_density_smooth[layer_peaks_idx[i - 1] : peak]\n",
    "            )\n",
    "\n",
    "        if i + 1 == len(layer_peaks_idx):\n",
    "            right_edge = (\n",
    "                peak + np.where(layer_density_smooth[peak:] == 0)[0][0]\n",
    "            )  # first zero value after the final peak\n",
    "        else:\n",
    "            right_edge = peak + np.argmin(\n",
    "                layer_density_smooth[peak : layer_peaks_idx[i + 1]]\n",
    "            )\n",
    "        layer_left_edge_idx.append(left_edge)\n",
    "        layer_right_edge_idx.append(right_edge)\n",
    "        # calculate count\n",
    "        layer_sa = (\n",
    "            layer_density_smooth[left_edge : right_edge + 1]\n",
    "            * area_dim[left_edge : right_edge + 1]\n",
    "        )\n",
    "        layer_sa_list.append(np.sum(layer_sa))\n",
    "        # calculate centre of mass radius\n",
    "        radius_sum = np.sum(layer_sa * range_dim[left_edge : right_edge + 1])\n",
    "        layer_weighted_centre_list.append(radius_sum / np.sum(layer_sa))\n",
    "\n",
    "    return layer_left_edge_idx, layer_right_edge_idx, layer_sa_list, layer_weighted_centre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(image_ffn, c_coord, ref_coord, emb_coord, img_ref_mm):\n",
    "\n",
    "    \"\"\"\n",
    "    primary function for analysing hailstone layers\n",
    "\n",
    "    Parameter:\n",
    "    ----------\n",
    "    image_ffn: string\n",
    "        path to image filename (must be resized first using resize_img.ipynb)\n",
    "    c_coord: list of two floats\n",
    "        pixel coordinates of hailstone centre [cx, cy]\n",
    "    ref_coord: list of two lists (which contain floats)\n",
    "        pixel coordinates of reference measurement start and end point [x_points_list, y_points_list]\n",
    "    emb_coord: list of two lists (which contain floats)\n",
    "        pixel coordinates of polygon boundary for embryo [x_points_list, y_points_list]\n",
    "    img_ref_mm: float\n",
    "        reference measurement for ref_coord in units of mm\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # parameters \n",
    "    gaussian_filter_sigma = 4 #sigma value used for gaussian smoothing filter\n",
    "    azimuth_spacing = 5  # spacing between transects (degrees)\n",
    "    target_pixel_size = 30 #used to resize image and for measurements, units of pix/mm\n",
    "    \n",
    "    # for detecting layers within each ray (step 1)\n",
    "    ray_prominence = 25  # minimum vertical distance to neighbouring samples to define a peak (relative value; Image intensity units)\n",
    "    ray_distance = 2*target_pixel_size  # minimum horizontal distance in samples between neighbouring peaks (mm)\n",
    "    ray_height = 80  # minimum height of peaks (absolute value; Image intensity units)\n",
    "    \n",
    "    # for detecting layers from all rays (step 2)\n",
    "    layer_smoothing = 10 #moving average window applied to smooth layer density analysis (pixel units)\n",
    "    layer_min_with = int(30/azimuth_spacing)  # minimum width used to define a layer azi dim steps (deg)\n",
    "    layer_prominence = 10  # minimum vertical distance to neighbouring samples to define a layer (relative value; opaque layer count)\n",
    "    layer_distance = 2*target_pixel_size   # minimum horizontal distance in samples between neighbouring layers (Pixels)\n",
    "\n",
    "    # extract image ID\n",
    "    img_fn = os.path.basename(image_ffn)\n",
    "    img_id = img_fn[0:2]\n",
    "    print(\"processing\", image_ffn)\n",
    "    \n",
    "    # unpack lists\n",
    "    cx, cy = c_coord\n",
    "    ref_coord_x, ref_coord_y = ref_coord\n",
    "    \n",
    "    # work out pixel scaling using reference length\n",
    "    ref_len = np.sqrt(\n",
    "        (ref_coord_x[0] - ref_coord_x[1]) ** 2 + (ref_coord_y[0] - ref_coord_y[1]) ** 2\n",
    "    )\n",
    "    ref_pix_mm = ref_len / img_ref_mm #pixels/mm\n",
    "    #scaling to resize image\n",
    "    resize_scaling = target_pixel_size/ref_pix_mm #ratio\n",
    "    \n",
    "    # read image file using opencv2\n",
    "    img_data = cv.imread(image_ffn)\n",
    "    # transform image into hsv colorspace\n",
    "    img_data_hls = cv.cvtColor(img_data, cv.COLOR_BGR2HLS)\n",
    "    # extract luminosity channel\n",
    "    lum_img = img_data_hls[:, :, 1]\n",
    "    #rescale to ensure consistent pixel size\n",
    "    lum_img = transform.rescale(lum_img, resize_scaling,\n",
    "                       anti_aliasing=True)\n",
    "    img_size = np.shape(lum_img)\n",
    "    # apply gaussian filter\n",
    "    lum_img_smooth = filters.gaussian(lum_img, sigma=gaussian_filter_sigma) * 255\n",
    "    \n",
    "    #rescale annotations\n",
    "    cx = cx*resize_scaling\n",
    "    cy = cy*resize_scaling\n",
    "    ref_coord_x = np.array(ref_coord_x)*resize_scaling\n",
    "    ref_coord_y = np.array(ref_coord_y)*resize_scaling\n",
    "\n",
    "    # work out embryo surface area\n",
    "    if emb_coord is None:\n",
    "        emb_sa = None\n",
    "    else:\n",
    "        # calculate surface area (rescaling)\n",
    "        emb_coord_x = np.array(emb_coord[0])*resize_scaling\n",
    "        emb_coord_y = np.array(emb_coord[1])*resize_scaling\n",
    "        emb_sa = area_shapely(emb_coord_x, emb_coord_y) / (target_pixel_size**2)\n",
    "    \"\"\"\n",
    "    PEAK ANALYSIS (FOR EACH TRANSECTS)\n",
    "    \"\"\"\n",
    "    \n",
    "    # define and plot transect lines\n",
    "    pixel_range = np.max(img_size)  # pixels (max possible distance)\n",
    "    # init dimenions for transects\n",
    "    azimuth_dim = np.arange(0, 360, azimuth_spacing)\n",
    "    range_dim = np.arange(0, pixel_range)\n",
    "    range_bin = range_dim[1] - range_dim[0]\n",
    "    azi_bin = azimuth_dim[1] - azimuth_dim[0]\n",
    "    # calculate area of each ray bin (pixel units\n",
    "    area_dim = np.zeros_like(range_dim)\n",
    "    for i, bin_range in enumerate(range_dim):\n",
    "        area_dim[i] = (\n",
    "            (\n",
    "                ((bin_range + (range_bin / 2)) ** 2) * math.pi\n",
    "                - ((bin_range - (range_bin / 2)) ** 2) * math.pi\n",
    "            )\n",
    "            / 360\n",
    "            * azi_bin\n",
    "        )\n",
    "\n",
    "    # init array to store layers (-1: outside, 0: translucent, 1: opaque, 2: rejected opaque \n",
    "    layer_array = np.zeros((pixel_range, len(azimuth_dim))) - 1  # set all to be outside\n",
    "\n",
    "    # init lists for debugging\n",
    "    line_x_list = []\n",
    "    line_y_list = []\n",
    "    line_lum_list = []\n",
    "    peaks_idx_list = []\n",
    "    peaks_width_list = []\n",
    "    # init lists for analysis/plotting\n",
    "    peaks_x_list = []\n",
    "    peaks_y_list = []\n",
    "    peaks_azi_list = []\n",
    "    cl_x_list = []\n",
    "    cl_y_list = []\n",
    "    cr_x_list = []\n",
    "    cr_y_list = []\n",
    "    edge_idx_list = []\n",
    "\n",
    "    # for each azimuth, analyse the transect.\n",
    "    for i, azi in enumerate(azimuth_dim):\n",
    "        # create indicies for lines from centroid along search azimuth rays\n",
    "        end_x = int(\n",
    "            cx + pixel_range * math.cos(math.radians(azi))\n",
    "        )\n",
    "        end_y = int(cy + pixel_range * math.sin(math.radians(azi)))\n",
    "        # generate line points\n",
    "        line_x = np.linspace(cx, end_x, pixel_range).astype(np.int)\n",
    "        line_y = np.linspace(cy, end_y, pixel_range).astype(np.int)\n",
    "        # enforce boundaries\n",
    "        mask_x = np.logical_and(line_x >= 0, line_x <= img_size[1] - 1)\n",
    "        mask_y = np.logical_and(line_y >= 0, line_y <= img_size[0] - 1)\n",
    "        mask = np.logical_and(mask_x, mask_y)\n",
    "        line_x = line_x[mask]\n",
    "        line_y = line_y[mask]\n",
    "\n",
    "        # extract data along transect\n",
    "        line_lum = lum_img_smooth[line_y, line_x].astype(int)\n",
    "        # measure peaks along traject using scipy find_peaks function: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html\n",
    "        peaks_idx, _ = scipy.signal.find_peaks(\n",
    "            line_lum,\n",
    "            prominence=ray_prominence,\n",
    "            distance=ray_distance,\n",
    "            height=ray_height,\n",
    "        )\n",
    "\n",
    "        # find edges of peaks in trasect, and edge of hailstone\n",
    "        left_idx, right_idx, new_peak_idx, edge_idx = find_peak_edges(\n",
    "            line_lum, peaks_idx, target_pixel_size\n",
    "        )\n",
    "\n",
    "        # create representative array from peak edges and hailstone edge for storing in layer_array\n",
    "        layer_vec = np.zeros(\n",
    "            pixel_range,\n",
    "        )\n",
    "        for j, _ in enumerate(new_peak_idx):\n",
    "            layer_vec[left_idx[j] : right_idx[j] + 1] = 1\n",
    "        layer_vec[edge_idx:] = -1\n",
    "        layer_array[:, i] = layer_vec\n",
    "\n",
    "        # skip storing layer parameters if there's no peaks\n",
    "        if len(new_peak_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        # store transect outputs for debugging\n",
    "        line_x_list.append(line_x)\n",
    "        line_y_list.append(line_y)\n",
    "        line_lum_list.append(line_lum)\n",
    "        peaks_idx_list.append(new_peak_idx)\n",
    "        peaks_width_list.append(right_idx - left_idx)\n",
    "        # store transect outputs for layer analysis and plotting\n",
    "        peaks_x_list.append(line_x[new_peak_idx])\n",
    "        peaks_y_list.append(line_y[new_peak_idx])\n",
    "        peaks_azi_list.append(np.zeros_like(new_peak_idx) + azi)\n",
    "        cl_x_list.append(line_x[left_idx])\n",
    "        cl_y_list.append(line_y[left_idx])\n",
    "        cr_x_list.append(line_x[right_idx])\n",
    "        cr_y_list.append(line_y[right_idx])\n",
    "        edge_idx_list.append(edge_idx)\n",
    "\n",
    "    \"\"\"\n",
    "    LAYER ANALYSIS (ACROSS ALL TRANSECTS)\n",
    "    \"\"\"\n",
    "    # flatten centre info arrays\n",
    "    cl_x_array = np.concatenate(cl_x_list).ravel() # left x values\n",
    "    cl_y_array = np.concatenate(cl_y_list).ravel() # left y values\n",
    "    cr_x_array = np.concatenate(cr_x_list).ravel() # right x values\n",
    "    cr_y_array = np.concatenate(cr_y_list).ravel() # right y values\n",
    "    peak_idx_array = np.concatenate(peaks_idx_list).ravel() # peak index\n",
    "    peak_x_array = np.concatenate(peaks_x_list).ravel() # peak location x\n",
    "    peak_y_array = np.concatenate(peaks_y_list).ravel() # peak location y\n",
    "    peaks_azi_array = np.concatenate(peaks_azi_list).ravel() # peak azimuth\n",
    "\n",
    "    # remove regions from layer_array which have a continuous azuimuthal length of less than layer_min_with\n",
    "    layer_label = morphology.label(layer_array == 1) #label regions\n",
    "    label_max = np.max(layer_label)\n",
    "    azimuth_grid, _ = np.meshgrid(azimuth_dim, range_dim) #create azimuthal grid\n",
    "    for label in range(1, label_max + 1):\n",
    "        #determine azimuthal width by number of unique azimuthal values\n",
    "        unqiue_azi_set = np.unique(azimuth_grid[layer_label == label])\n",
    "        azi_width = len(unqiue_azi_set) \n",
    "        if azi_width <= layer_min_with:\n",
    "            layer_array[layer_label == label] = 2 #assigned to \"filtered out\"  \n",
    "\n",
    "    # compute number of times an opaque layer detected as a function of range for all transects\n",
    "    layer_valid = layer_array == 1\n",
    "    layer_density = np.sum(layer_valid, axis=1)\n",
    "    # smooth to reduce noise\n",
    "    layer_density_smooth = moving_average(layer_density, layer_smoothing)\n",
    "    # find layers in opaque density analysis\n",
    "    layer_peaks_idx, _ = scipy.signal.find_peaks(\n",
    "        layer_density_smooth, prominence=layer_prominence, distance=layer_distance\n",
    "    )\n",
    "\n",
    "    # # compute the normalised (radially) layers dataset\n",
    "    # norm_range = int(pixel_range/2)\n",
    "    # norm_layer_array = np.zeros((norm_range, len(azimuth_dim))) - 1 \n",
    "    # norm_range_dim = np.linspace(0, 100, norm_range)\n",
    "    # for i, azi in enumerate(azimuth_dim):\n",
    "    #     input_radial = layer_array[:edge_idx_list[i],i]\n",
    "    #     input_range = np.linspace(0, 100, len(input_radial))\n",
    "    #     f = interpolate.interp1d(input_range, input_radial, kind='nearest')\n",
    "    #     norm_layer_array[:,i] = f(norm_range_dim)\n",
    "    \n",
    "    #process layer peaks to find edges, and layer stats\n",
    "    layer_left_edge_idx, layer_right_edge_idx, layer_sa_list, layer_weighted_centre_list = process_layers(layer_peaks_idx, layer_density_smooth, range_dim, area_dim)\n",
    "\n",
    "    \"\"\"\n",
    "    PLOTTING\n",
    "    \"\"\"\n",
    "    \n",
    "#     fig = plt.figure(facecolor=\"white\", figsize=[12, 6])\n",
    "#     fig.suptitle(f\"Hailstone {img_id}\", fontsize=16)\n",
    "    \n",
    "#     plt.subplot(121)\n",
    "    \n",
    "#     # define colormap for layer_array\n",
    "#     hail_colors = [\"black\", \"dimgrey\", \"white\", \"yellow\"]\n",
    "#     hail_cmap = colors.ListedColormap(hail_colors)\n",
    "#     #plot layer_array as image\n",
    "#     img = plt.pcolor(\n",
    "#         azimuth_dim, range_dim/target_pixel_size, layer_array, vmin=-1.5, vmax=2.5, cmap=hail_cmap\n",
    "#     )\n",
    "#     #create colorbar\n",
    "#     cbar = plt.colorbar(img, ticks=[-1, 0, 1, 2], orientation=\"horizontal\")\n",
    "#     cbar.ax.set_xticklabels(\n",
    "#         [\"Background\", \"Translucent layer\", \"Opaque layer\", \"Invalid opaque layer\"],\n",
    "#     fontsize=8)\n",
    "#     plt.axis(\"auto\")\n",
    "#     plt_range = np.max(edge_idx_list)/target_pixel_size + 5\n",
    "#     plt.ylim([0, plt_range])\n",
    "#     plt.xlabel(\"Azimuth (deg.)\")\n",
    "#     plt.ylabel(\"Distance from embryo centroid (mm)\")\n",
    "#     plt.title(\"Layer pixels detected from transects\", fontsize=14)\n",
    "    \n",
    "#     plt.subplot(122)\n",
    "#     # define colormap for layer_array\n",
    "#     hail_colors = [\"black\", \"dimgrey\", \"white\", \"yellow\"]\n",
    "#     hail_cmap = colors.ListedColormap(hail_colors)\n",
    "#     #plot layer_array as image\n",
    "#     img = plt.pcolor(\n",
    "#         azimuth_dim, norm_range_dim, norm_layer_array, vmin=-1.5, vmax=2.5, cmap=hail_cmap\n",
    "#     )\n",
    "#     #create colorbar\n",
    "#     cbar = plt.colorbar(img, ticks=[-1, 0, 1, 2], orientation=\"horizontal\")\n",
    "#     cbar.ax.set_xticklabels(\n",
    "#         [\"Background\", \"Translucent layer\", \"Opaque layer\", \"Invalid opaque layer\"],\n",
    "#     fontsize=8)\n",
    "#     plt.axis(\"auto\")\n",
    "#     plt.ylim([0, 100])\n",
    "#     plt.xlabel(\"Azimuth (deg.)\")\n",
    "#     plt.ylabel(\"Normalised Distance\")\n",
    "#     plt.title(\"Noramlised Layer pixels detected from transects\", fontsize=14)\n",
    "    \n",
    "#     # export and save figure\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f\"{out_root}/layer_comparison_{os.path.basename(image_ffn)}\")\n",
    "#     plt.clf()\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # MAIN PLOT\n",
    "    ###########################################################################################\n",
    "    \n",
    "    fig = plt.figure(facecolor=\"white\", figsize=[12, 11])\n",
    "    fig.suptitle(f\"Hailstone {img_id}\", fontsize=16)\n",
    "\n",
    "    ###########################################################################################\n",
    "    # subplot 1: hailstone image overlaid with annotations and trajections\n",
    "    ###########################################################################################\n",
    "    \n",
    "    ax = plt.subplot(221)\n",
    "    plt.gca().invert_yaxis()\n",
    "    # plot image\n",
    "    plt.imshow(lum_img_smooth, cmap=\"gray\")\n",
    "    for i, _ in enumerate(cl_x_array):\n",
    "        if i == 0:\n",
    "            # mark peaks\n",
    "            plt.plot(peak_x_array[i], peak_y_array[i], \"b.\", markersize=8, label=\"Local peak\")\n",
    "            # mark edges\n",
    "            plt.plot(\n",
    "                [cl_x_array[i], cr_x_array[i]],\n",
    "                [cl_y_array[i], cr_y_array[i]],\n",
    "                \"b-\",\n",
    "                label=\"Local peak width\",\n",
    "            )\n",
    "        else:  # plot without labels\n",
    "            # mark peaks\n",
    "            plt.plot(peak_x_array[i], peak_y_array[i], \"b.\", markersize=8)\n",
    "            # mark edges\n",
    "            plt.plot(\n",
    "                [cl_x_array[i], cr_x_array[i]], [cl_y_array[i], cr_y_array[i]], \"b-\"\n",
    "            )\n",
    "    # plot centroid\n",
    "    plt.plot(cx, cy, \"r*\", markersize=16, label=\"Embryo centre\")\n",
    "    # plot embryo\n",
    "    try:\n",
    "        plt.plot(emb_coord_x, emb_coord_y, \"r-\", linewidth=3, label=\"Embryo edge\")\n",
    "    except:\n",
    "        # no dry embryo\n",
    "        pass\n",
    "    # plot reference measurement\n",
    "    plt.plot(ref_coord_x, ref_coord_y, \"r--\", linewidth=3, label=\"Reference measurement\")\n",
    "    \n",
    "    \n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"(a) Manual Annotations and Transects\", fontsize=14)\n",
    "\n",
    "    ###########################################################################################\n",
    "    # subplot 2: plot layer_array as a azimuth/range image to explore layers\n",
    "    ###########################################################################################\n",
    "    plt.subplot(222)\n",
    "    \n",
    "    # define colormap for layer_array\n",
    "    hail_colors = [\"black\", \"dimgrey\", \"white\", \"yellow\"]\n",
    "    hail_cmap = colors.ListedColormap(hail_colors)\n",
    "    #plot layer_array as image\n",
    "    img = plt.pcolor(\n",
    "        azimuth_dim, range_dim/target_pixel_size, layer_array, vmin=-1.5, vmax=2.5, cmap=hail_cmap\n",
    "    )\n",
    "    #create colorbar\n",
    "    cbar = plt.colorbar(img, ticks=[-1, 0, 1, 2], orientation=\"horizontal\")\n",
    "    cbar.ax.set_xticklabels(\n",
    "        [\"Background\", \"Translucent layer\", \"Opaque layer\", \"Invalid opaque layer\"],\n",
    "    fontsize=8)\n",
    "    plt.axis(\"auto\")\n",
    "    plt_range = np.max(edge_idx_list)/target_pixel_size + 5\n",
    "    plt.ylim([0, plt_range])\n",
    "    plt.xlabel(\"Azimuth (deg.)\")\n",
    "    plt.ylabel(\"Distance from embryo centroid (mm)\")\n",
    "    plt.title(\"(b) Candidate layer regions detected from transects\", fontsize=14)\n",
    "\n",
    "    ###########################################################################################\n",
    "    # subplot 3: plot layer density as a function of range to explore layer extraction\n",
    "    ###########################################################################################\n",
    "    plt.subplot(223)\n",
    "    #plot range density\n",
    "    plt.plot(range_dim/target_pixel_size, layer_density_smooth, \"k--\")\n",
    "    #plot layer peak locations\n",
    "    plt.plot(\n",
    "        range_dim[layer_peaks_idx]/target_pixel_size,\n",
    "        layer_density_smooth[layer_peaks_idx],\n",
    "        marker=\"o\",\n",
    "        markerfacecolor=\"b\",\n",
    "        linewidth=0,\n",
    "        label=\"Peak\",\n",
    "        markersize=8,\n",
    "    )\n",
    "    #plot layer weighted centre locations\n",
    "    plt.plot(\n",
    "        np.array(layer_weighted_centre_list)/target_pixel_size,\n",
    "        layer_density_smooth[np.array(layer_weighted_centre_list).astype(\"int\")],\n",
    "        marker=\"o\",\n",
    "        markerfacecolor=\"k\",\n",
    "        linewidth=0,\n",
    "        label=\"Area weighted centre\",\n",
    "        markersize=8,\n",
    "    )\n",
    "    #plot left edge locations\n",
    "    plt.plot(\n",
    "        range_dim[layer_left_edge_idx]/target_pixel_size,\n",
    "        layer_density_smooth[layer_left_edge_idx],\n",
    "        marker=7,\n",
    "        markerfacecolor=\"b\",\n",
    "        linewidth=0,\n",
    "        label=\"Layer edge\",\n",
    "        markersize=8,\n",
    "    )\n",
    "    #plot right edge locations\n",
    "    plt.plot(\n",
    "        range_dim[layer_right_edge_idx]/target_pixel_size,\n",
    "        layer_density_smooth[layer_right_edge_idx],\n",
    "        marker=7,\n",
    "        markerfacecolor=\"b\",\n",
    "        linewidth=0,\n",
    "        markersize=8,\n",
    "    )\n",
    "    plt.xlim([0, plt_range])\n",
    "    plt.ylim([-1, np.max(layer_density_smooth) + 5])\n",
    "    plt.xlabel(\"Distance from embryo centroid (mm)\")\n",
    "    plt.ylabel(\"Layer aggregation\")\n",
    "    plt.title(\"(c) Consolidated transects\", fontsize=14)\n",
    "    plt.legend()\n",
    "\n",
    "    ###########################################################################################\n",
    "    # subplot 4: plot equivalent cross section\n",
    "    ###########################################################################################\n",
    "    ax = plt.subplot(224)\n",
    "    #setup axis\n",
    "    ax.set_xlabel(\"(mm)\")\n",
    "    ax.set_ylabel(\"(mm)\")\n",
    "    ax.set_facecolor(\"black\")\n",
    "    # draw hailstone edge using mean edge distance\n",
    "    mean_edge_radius = np.mean(edge_idx_list) / target_pixel_size #\n",
    "    background = plt.Circle((0, 0), mean_edge_radius, color=\"dimgrey\")\n",
    "    ax.add_artist(background)\n",
    "    output_sa_array = [] #this is exported as a stat, not plotted\n",
    "    output_inner_array = []\n",
    "    output_output_array = []\n",
    "    #for each layer\n",
    "    for i in range(len(layer_sa_list) - 1, -1, -1):  # loop backwards to plot inner layers first\n",
    "        r = layer_weighted_centre_list[i] / target_pixel_size\n",
    "        sa = layer_sa_list[i] / (target_pixel_size ** 2)\n",
    "        output_sa_array.append(sa)\n",
    "        #calculate the inner and outer radius of each layer, centred on the weighted centre for a given sa (units of mm)\n",
    "        r_inner = math.sqrt(r ** 2 - (sa / (2 * math.pi)))\n",
    "        r_outer = math.sqrt((sa / (2 * math.pi)) + r ** 2)\n",
    "        \n",
    "        if r_outer>mean_edge_radius:\n",
    "            mean_edge_radius=r_outer\n",
    "        output_inner_array.append(r_inner)\n",
    "        output_output_array.append(r_outer)\n",
    "        \n",
    "        #plot layer as a white circle overlaid with a grey circle\n",
    "        circle_inner = plt.Circle((0, 0), r_inner, color=\"dimgrey\")\n",
    "        circle_outer = plt.Circle((0, 0), r_outer, color=\"white\")\n",
    "        ax.add_artist(circle_outer)\n",
    "        ax.add_artist(circle_inner)\n",
    "    # draw equivalent embryo\n",
    "    if emb_sa is not None:\n",
    "        # use embryo surface area to calculate equivalent radius\n",
    "        r_embryo = np.sqrt(emb_sa / math.pi)\n",
    "        circle_embryo = plt.Circle((0, 0), r_embryo, color=\"white\")\n",
    "        ax.add_artist(circle_embryo)\n",
    "    grid_coord = [-35, -25, -15, -5, 5, 15, 25, 35]\n",
    "    for i in grid_coord:\n",
    "        plt.plot([i, i], [-40, 40], \"y:\", lw=2)\n",
    "        plt.plot([-40, 40], [i, i], \"y:\", lw=2)\n",
    "        \n",
    "    ax.set_xlim((-40, 40))\n",
    "    ax.set_ylim((-40, 40))\n",
    "    ax.set_aspect('equal')\n",
    "    plt.title(\"(d) Equivalent Circular Cross Section\", fontsize=14)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # export and save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{out_root}/analysis_{os.path.basename(image_ffn)}\")\n",
    "    plt.clf()\n",
    "    plt.close(\"all\")\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # second plot: plot equivalent cross section in it's own figure\n",
    "    ###########################################################################################\n",
    "    \n",
    "    # draw equivalent circular hail in its own figure\n",
    "    fig = plt.figure(figsize=[10, 10])\n",
    "    fig.set_facecolor(\"k\")\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_facecolor(\"k\")\n",
    "    # draw entire hail\n",
    "    mean_edge_radius = np.mean(edge_idx_list) / target_pixel_size\n",
    "    background = plt.Circle((0, 0), mean_edge_radius, color=[0.5, 0.5, 0.5])\n",
    "    ax.add_artist(background)\n",
    "    for i in range(len(layer_sa_list) - 1, -1, -1):  # loop backwards to plot inner layers first\n",
    "        r = layer_weighted_centre_list[i] / target_pixel_size\n",
    "        sa = layer_sa_list[i] / (target_pixel_size ** 2)\n",
    "        #calculate the inner and outer radius of each layer, centred on the weighted centre for a given sa (units of mm)\n",
    "        r_inner = math.sqrt(r ** 2 - (sa / (2 * math.pi)))\n",
    "        r_outer = math.sqrt((sa / (2 * math.pi)) + r ** 2)\n",
    "        circle_inner = plt.Circle((0, 0), r_inner, color=[0.5, 0.5, 0.5])\n",
    "        circle_outer = plt.Circle((0, 0), r_outer, color=\"w\")\n",
    "        ax.add_artist(circle_outer)\n",
    "        ax.add_artist(circle_inner)\n",
    "    # draw equivalent embryo\n",
    "    if emb_sa is not None:\n",
    "        # use embryo surface area to calculate equivalent radius\n",
    "        r_embryo = np.sqrt(emb_sa / math.pi)\n",
    "        circle_embryo = plt.Circle((0, 0), r_embryo, color=\"w\")\n",
    "        ax.add_artist(circle_embryo)\n",
    "    # draw grids on plot\n",
    "    x = (np.arange(0, img_size[1]) - int(img_size[1] / 2)) / target_pixel_size\n",
    "    y = (np.arange(0, img_size[0]) - int(img_size[0] / 2)) / target_pixel_size\n",
    "    grid_coord = [-35, -25, -15, -5, 5, 15, 25, 35]\n",
    "    for i in grid_coord:\n",
    "        plt.plot([i, i], [-40, 40], \"y:\", lw=2)\n",
    "        plt.plot([-40, 40], [i, i], \"y:\", lw=2)\n",
    "    ax.set_xlim((-40, 40))\n",
    "    ax.set_ylim((-40, 40))\n",
    "    # export plot\n",
    "    ax.set_axis_off()\n",
    "    plt.savefig(\n",
    "        f\"{composite_eq_root}/resized_eq_{os.path.basename(image_ffn)}\",\n",
    "        bbox_inches=\"tight\",\n",
    "        pad_inches=0,\n",
    "    )\n",
    "    plt.clf()\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    # export stats\n",
    "    max_edge_radius = np.max(edge_idx_list) / target_pixel_size\n",
    "    np.savez(\n",
    "        f\"{stats_root}/stats_{img_id}.npz\",\n",
    "        mean_edge_radius = mean_edge_radius,\n",
    "        output_sa_array = np.array(output_sa_array),\n",
    "        output_inner_array = np.array(output_inner_array),\n",
    "        output_output_array = np.array(output_output_array)\n",
    "    )\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no dry embryo for 2\n",
      "no dry embryo for 5\n",
      "no dry embryo for 9\n",
      "no dry embryo for 24\n",
      "no dry embryo for 25\n",
      "no dry embryo for 26\n",
      "no dry embryo for 27\n",
      "no dry embryo for 29\n",
      "no dry embryo for 34\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build arguements for the worker function using reference_csv_ffn and via_json_ffn\n",
    "\"\"\"\n",
    "\n",
    "#read reference sizes dataset\n",
    "df = pd.read_csv(reference_csv_ffn)\n",
    "\n",
    "#build image file and centroid arguments from annotation json file\n",
    "worker_args_list = []\n",
    "with open(via_json_ffn) as json_fh:  \n",
    "    data = json.load(json_fh)\n",
    "    #for each image in the annoation file\n",
    "    for item in data.keys():\n",
    "        #extract image name and id\n",
    "        img_fn = data[item]['filename']\n",
    "        img_id = int(img_fn[0:2])\n",
    "        #extract shape variables\n",
    "        c_coord = None\n",
    "        ref_coord = None\n",
    "        emb_coord = None\n",
    "        for shape in data[item]['regions']:\n",
    "            shape = shape['shape_attributes']\n",
    "            if shape['name'] == 'point':\n",
    "                c_coord = [shape['cx'], shape['cy']]\n",
    "            if shape['name'] == 'polygon':                \n",
    "                emb_coord_x = shape['all_points_x']\n",
    "                emb_coord_y = shape['all_points_y']\n",
    "                #close polygon\n",
    "                emb_coord = [emb_coord_x + [emb_coord_x[0]], emb_coord_y + [emb_coord_y[0]]]\n",
    "            if shape['name'] == 'polyline':\n",
    "                ref_coord = [shape['all_points_x'], shape['all_points_y']]    \n",
    "        if emb_coord == None:\n",
    "            print('no dry embryo for', img_id)\n",
    "        #check for missing metadata\n",
    "        if c_coord == None or ref_coord == None:\n",
    "            print('error: missing json data for if', img_id)\n",
    "            continue\n",
    "        #extract reference measurement\n",
    "        try:\n",
    "            img_ref_mm = float(df.size_mm[df.id==img_id])\n",
    "        except:\n",
    "            print('error: failed to find reference measurement to match id', img_id)\n",
    "            continue\n",
    "        #build args\n",
    "        worker_args_list.append((f'{image_folder}/{img_fn}', c_coord, ref_coord, emb_coord, img_ref_mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/01.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/02.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/03.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/04.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/05.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/06.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/07.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/08.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/09.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/10.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/11.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/12.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/13.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/14.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/15.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/16.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/17.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/18.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/19.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/20.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/21.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/22.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/23.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/24.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/25.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/26.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/27.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/28.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/29.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/30.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/31.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/32.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/33.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/34.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/35.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/36.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/37.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/38.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/39.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/40.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/41.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/42.png\n",
      "processing /home/meso/data/cross-section-paper-data/analysis/photos/43.png\n"
     ]
    }
   ],
   "source": [
    "#run worker for all images\n",
    "for item in worker_args_list:\n",
    "    worker(*item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
